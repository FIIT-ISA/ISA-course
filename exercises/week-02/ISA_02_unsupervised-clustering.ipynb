{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcedd80-f8d0-4f61-9608-5ed524dcee69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:41.257178700Z",
     "start_time": "2024-03-22T22:47:40.257643Z"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b30d08303fc6c4c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Clustering\n",
    "Clustering is a data mining technique that groups unlabeled data based on their similarities or differences. Clustering algorithms process raw, unclassified data objects into groups represented by structures or patterns in the information. Clustering algorithms can be categorized into a few types, including exclusive, overlapping, hierarchical, and probabilistic.\n",
    "\n",
    "**Datasets:**\n",
    "- **Online Shoppers Intention** https://www.kaggle.com/datasets/henrysue/online-shoppers-intention\n",
    "- Sakar, C.O., Polat, S.O., Katircioglu, M. and Kastro, Y., 2019. Real-time prediction of online shoppers’ purchasing intention using multilayer perceptron and LSTM recurrent neural networks. Neural Computing and Applications, 31(10), pp.6893-6908, 2019. https://link.springer.com/article/10.1007/s00521-018-3523-0\n",
    "- **Credit Card Dataset for Clustering** https://www.kaggle.com/datasets/arjunbhasin2013/ccdata for Probabilistic Clustering\n",
    "\n",
    "**Sources:**\n",
    "- https://www.techtarget.com/searchenterpriseai/definition/unsupervised-learning\n",
    "- https://www.datacamp.com/blog/introduction-to-unsupervised-learning\n",
    "- https://www.kaggle.com/code/vipulgandhi/gaussian-mixture-models-clustering-explained/notebook\n",
    "- [IBM Explainers](https://www.ibm.com/topics/unsupervisedlearning#:~:text=Unsupervised%20learning%2C%20also%20known%20as,the%20need%20for%20human%20intervention)\n",
    "- https://www.kaggle.com/code/thuggy/predicting-purchasing-intention\n",
    "- https://builtin.com/data-science/elbow-method\n",
    "- https://www.kdnuggets.com/2023/04/exploring-unsupervised-learning-metrics.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254b17e8-bd23-43d5-88e1-4842d666cb35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:41.977883100Z",
     "start_time": "2024-03-22T22:47:40.302210500Z"
    }
   },
   "outputs": [],
   "source": [
    "# ! pip install scikit-fuzzy\n",
    "# ! pip install sammon-mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf9056ff2b0e99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:42.300647200Z",
     "start_time": "2024-03-22T22:47:40.325822200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import skfuzzy as fuzz\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_score\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sammon import sammon\n",
    "from sklearn.manifold import trustworthiness\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c061575ee446145",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47113f4aa1434004",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:42.981900700Z",
     "start_time": "2024-03-22T22:47:40.351536500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/online_shoppers_intention.csv', encoding=\"utf-8\")\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4f05a427a047d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:43.074672Z",
     "start_time": "2024-03-22T22:47:40.529349200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The first few rows of the dataset are displayed using df.head(), providing an initial glimpse into the data's structure and the types of values it contains.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662f808cadde9e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:43.127931500Z",
     "start_time": "2024-03-22T22:47:40.574261600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(u'- Number of rows: {}'.format(df.shape[0]))\n",
    "print(u'- Number of columns: {}'.format(df.shape[1]))\n",
    "print(u'- Name of independent variables: {}'.format(list(df.columns[:-1])))\n",
    "print(u'- Name of target: {}'.format(list(df.columns[-1:])))\n",
    "print(u'- Dataset shape:{}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a2a5f9bdf8045",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:43.239864700Z",
     "start_time": "2024-03-22T22:47:40.597316100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63098c77bc2569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:43.353288Z",
     "start_time": "2024-03-22T22:47:40.694056500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.groupby('Month', observed=False).agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e9e8c10df77b3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Upon examining the 'Month' column, it was observed that most months are abbreviated (e.g., JUL, AUG, DEC), but one entry uses 'June' instead of 'Jun'. To maintain consistency, this will be corrected. Additionally, there is an absence of data for January and April; these months will be excluded from the analysis for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274f7dab05e18fb0",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Checking for Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d489038f475578f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:43.615269900Z",
     "start_time": "2024-03-22T22:47:40.737143500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.notnull().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a41053b721874",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:43.810939300Z",
     "start_time": "2024-03-22T22:47:40.770380400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df1 = df.drop_duplicates()\n",
    "# dropping any rows with missing values (NaN) from the DataFrame\n",
    "df1 = df1.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988068ccc2aa6381",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:47:43.911797200Z",
     "start_time": "2024-03-22T22:47:40.804973400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Numerical & Categorical columns\n",
    "num_cols = [x for x in df1.select_dtypes(include=np.number)]\n",
    "cat_cols = [x for x in df1.select_dtypes(exclude=np.number)]\n",
    "print(\"There are\", len(num_cols), \"numerical columns and\", len(cat_cols), \"categorical columns in the dataset\\n\")\n",
    "print(\"Numerical columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6405cc6bad9c756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:00.077066500Z",
     "start_time": "2024-03-22T22:47:40.840030600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    " # Numerical Columns Plot & Box Plot \n",
    "df1[num_cols].plot(kind='density', subplots=True, layout=(4,4), sharex=False, figsize=(25, 12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1843e17061dd0f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:03.534049800Z",
     "start_time": "2024-03-22T22:48:00.082559300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df1[num_cols].plot(kind='box', subplots=True, layout=(4,4), sharex=False, figsize=(25, 12));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283df27decb94218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:04.155071100Z",
     "start_time": "2024-03-22T22:48:03.489359500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def show_count_plot(df, col, rotation=0, figsize=(12, 6), hue=None, color='orange'):\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = sns.countplot(x=df[col],\n",
    "                       order=df[col].value_counts(ascending=False).head(10).index,\n",
    "                       hue=hue, color=color)\n",
    "    ax.set_ylabel('Count', size=10)\n",
    "    ax.set_xlabel(col, size=10)\n",
    "    plt.xticks(rotation=rotation, size=10)\n",
    "    plt.yticks(size=10)\n",
    "    \n",
    "    # Get absolute and relative values\n",
    "    abs_values = df[col].value_counts(ascending=False).head(10)\n",
    "    rel_values = df[col].value_counts(ascending=False, normalize=True).head(10).values * 100\n",
    "    labels = [f'{p[0]} ({p[1]:.0f}%)' for p in zip(abs_values, rel_values)]\n",
    "    \n",
    "    # Set labels on bars\n",
    "    ax.bar_label(container=ax.containers[0], labels=labels, size=10)\n",
    "\n",
    "    plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fb34a962d4e591",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Administrative and Administrative Duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4113e032eb09c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:04.344912Z",
     "start_time": "2024-03-22T22:48:03.526271600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'Administrative', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc62f1c18fd322",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Approximately 50% of users did not visit the Administrative page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2ec925ab743b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:05.215590900Z",
     "start_time": "2024-03-22T22:48:04.264986200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'Administrative_Duration', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc5b93cf546148",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Informational and Informational_Duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763e65da65b6b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:06.022054Z",
     "start_time": "2024-03-22T22:48:04.978760800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'Informational', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf090f7e3f442ad8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Approximately 80% of users did not visit the informational page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac825f1fc6ffbfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:06.741035300Z",
     "start_time": "2024-03-22T22:48:05.785554900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'Informational_Duration', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9367ed76334a5437",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**ProductRelated and ProductRelated_Duration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02983f24bb03f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:07.473014100Z",
     "start_time": "2024-03-22T22:48:06.516968700Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'ProductRelated', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd2f61afad828b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:08.164958Z",
     "start_time": "2024-03-22T22:48:07.192180900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'ProductRelated_Duration', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4521b58448c93c96",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "ProductRelated pages were visited relatively evenly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99261756b18e5c8a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**SpecialDay**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e5993cfda03cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:08.811076300Z",
     "start_time": "2024-03-22T22:48:07.854434400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'SpecialDay', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac1a09173b9f25",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "About 90% of visitors are not affected by Special Days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105e9d3481596b6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**OperatingSystems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f446c44865bf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:09.480584600Z",
     "start_time": "2024-03-22T22:48:08.445685900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'OperatingSystems', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c4b8d475650cd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The top 3 operating systems are: 2, 1, and 3. Over 50% of our visitors use OS 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24169dcb404c3efa",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Browser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46109ba4b7233f99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:10.190339800Z",
     "start_time": "2024-03-22T22:48:09.025162300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1,'Browser', figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ddfff54541c36d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The top 3 browsers are: 2, 1, and 4. You can see that 65% of visitors come from browser 2, and over 85% come from browsers 2 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a15fe7d69546fc",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a194bbcafd6ea59a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:10.807570200Z",
     "start_time": "2024-03-22T22:48:09.789066600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1, 'Month',figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0ec1672079a1c2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The most visited months are May, November and March. However, data for January and April was missing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f07ecdedb32ccd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Visitor Type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd8555c9aa3a1ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:11.523270800Z",
     "start_time": "2024-03-22T22:48:10.476581Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1, 'VisitorType',figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dc9553cebaf623",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The majority of visitors return to the website, with 86% returning customers vs. 14% new customers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35787d9717da0980",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Weekend**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cb89d815391e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:11.524227300Z",
     "start_time": "2024-03-22T22:48:10.949550600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1, 'Weekend',figsize=(30,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eea48402c2f2b41",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "77% of visitors do not visit on weekends, while 23% visit on weekends. Since there are 5 days on weekdays and 2 days on weekends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3496f0242d194a41",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Revenue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd317bb7a244d6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:13.008577600Z",
     "start_time": "2024-03-22T22:48:11.360119200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "show_count_plot(df1, 'Revenue',figsize=(20,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1971e19a26dfdef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6b08c02443a4e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:13.009577Z",
     "start_time": "2024-03-22T22:48:11.718090800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define the mapping of months to numbers\n",
    "month_mapping = {'Feb': 2, 'Mar': 3, 'May': 5, 'Oct': 10, 'June': 6, 'Jul': 7, 'Aug': 8, 'Nov': 11, 'Sep': 9, 'Dec': 12}\n",
    "\n",
    "# Use .loc to set the 'Month' column values in the original DataFrame\n",
    "df1.loc[:, 'Month'] = df1['Month'].map(month_mapping)\n",
    "\n",
    "# Verify the change\n",
    "print(df1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b57ca2707bd08a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:13.009577Z",
     "start_time": "2024-03-22T22:48:11.746399Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# visitor_type column\n",
    "visitor_encoded = pd.get_dummies(df1['VisitorType'], prefix='VisitorType', drop_first = True)\n",
    "df1 = pd.concat([df1, visitor_encoded], axis=1).drop(['VisitorType'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6f390ed818ab1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:13.009577Z",
     "start_time": "2024-03-22T22:48:11.786382300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert variable to Int type\n",
    "df1['Revenue'] = df1['Revenue'].astype(int)\n",
    "df1['Weekend'] = df1['Weekend'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cc0d37d9902b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:15.102236700Z",
     "start_time": "2024-03-22T22:48:11.814765400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Check correlation coefficient\n",
    "df_Corr = df1.corr()\n",
    "fig, ax = plt.subplots(figsize=(16,16))  \n",
    "sns.heatmap(df_Corr, xticklabels=df_Corr.columns, yticklabels=df_Corr.columns, annot=True, cmap = 'YlOrBr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2d00e656c6795e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Remove unnecessary columns\n",
    "\n",
    "In the case of the Month column, it was removed because it was incomplete data missing January and April. As a result of heatmap visualization, it was decided to remove independent variables whose correlation coefficient with the dependent variable was less than 0.05. (based on absolute value) So let's remove the Month, Browser, OperatingSystems, Region, TrafficType, Weekend, and VisitorType_Other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84c2625d0f9f00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:15.802760500Z",
     "start_time": "2024-03-22T22:48:15.101221200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Dropping specified columns\n",
    "df2 = df1.drop(['Month','Browser','OperatingSystems','Region','TrafficType','Weekend','VisitorType_Other'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2654214588d2582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:53:16.049485600Z",
     "start_time": "2024-03-22T22:53:15.924986900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f03626db173810",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Clustering Algorithm Metrics\n",
    "### **Elbow method**\n",
    "\n",
    "The elbow method involves finding the optimal k via a graphical representation. It works by finding the within-cluster sum of square (WCSS), i.e. the sum of the square distance between points in a cluster and the cluster centroid.\n",
    "\n",
    "The elbow graph shows WCSS values on the y-axis corresponding to the different values of K on the x-axis. When we see an elbow shape in the graph, we pick the K-value where the elbow gets created. We can call this the elbow point. Beyond the elbow point, increasing the value of ‘K’ does not lead to a significant reduction in WCSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d8c515d3c20d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-22T22:48:17.173848900Z",
     "start_time": "2024-03-22T22:48:16.618141400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "wcss = []\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    kmeans.fit(df2)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow method\n",
    "plt.plot(range(1, 11), wcss, marker='o')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5764d81d27ae4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Looking at your plot, the \"elbow\" seems to be at the point where the rate of decrease sharply changes, which in this case is at k=3. \n",
    "This means that increasing the number of clusters from 2 to 3 gives a significant decrease in WCSS, but beyond 3 the decrease is more gradual. \n",
    "Thus, k=3 is likely a good choice for the number of clusters based on the Elbow Method applied to your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacef3b9ae1ac5a7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### **Silhouette Coefficient**\n",
    "\n",
    "Average silhouette approach measures the quality of a clustering. That is, it determines how well each object lies within its cluster. A high average silhouette width indicates a good clustering. The optimal number of clusters k is the one that maximize the average silhouette over a range of possible values for k. \n",
    "\n",
    "The algorithm can be computed as follow: \n",
    "• Compute clustering algorithm (e.g., k-means clustering) for different values of k. \n",
    "• For each k, calculate the average silhouette of observations (avg.sil). \n",
    "• Plot the curve of avg.sil according to the number of clusters k. \n",
    "• The location of the maximum is considered as the appropriate number of clusters.  \n",
    "\n",
    "The silhouette score falls within the range [-1, 1]. The silhouette score of 1 means that the clusters are very dense and nicely separated. \n",
    "The score of 0 means that clusters are overlapping. \n",
    "The score of less than 0 means that data belonging to clusters may be wrong/incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80e637a9efbe6f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:16.953033800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the KMeans for 3 clusters\n",
    "km = KMeans(n_clusters=3, random_state=42)\n",
    "# Fit the KMeans model\n",
    "km.fit_predict(df2)\n",
    "# Calculate Silhoutte Score\n",
    "score = silhouette_score(df2, km.labels_, metric='euclidean')\n",
    "# Print the score\n",
    "print('Silhouetter Coefficient: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc58700ec7da7f2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### **Calinski-Harabasz Index**\n",
    "\n",
    "The Calinski-Harabasz Index (also known as the Variance Ratio Criterion) is a metric used to evaluate the quality of clusters created by a clustering algorithm. A higher Calinski-Harabasz score relates to a model with better-defined clusters.\n",
    "\n",
    "The Calinski-Harabasz Index is defined as the ratio of the sum of between-clusters dispersion and of within-cluster dispersion for all clusters (where dispersion is defined as the sum of distances squared). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324acc81a26a6ed3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:16.961551Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fit KMeans and predict clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(df2)\n",
    "\n",
    "# Calculate Calinski-Harabasz Index\n",
    "ch_score = calinski_harabasz_score(df2, cluster_labels)\n",
    "print('Calinski-Harabasz Index: %.3f' % ch_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e851c988d80a9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### **Davies-Bouldin Index**\n",
    "\n",
    "The Davies-Bouldin Index is a validation metric that is used to evaluate clustering models. It is calculated as the average similarity measure of each cluster with the cluster most similar to it. In this context, similarity is defined as the ratio between inter-cluster and intra-cluster distances. As such, this index ranks well-separated clusters with less dispersion as having a better score.\n",
    "\n",
    "In practice, the DBI will usually be within a range that is specific to the dataset being analyzed. Lower values of the DBI indicate better clustering quality, with the minimum value of 0 being the best. High values suggest poor clustering, either due to clusters being too close to each other or because of high variance within the clusters.\n",
    "\n",
    "When using the DBI to evaluate the quality of clusters, one typically looks for the clustering solution that minimizes the DBI. It's common to calculate the DBI for various numbers of clusters and then choose the number of clusters that yields the lowest DBI, provided that the clustering solution is sensible and interpretable for the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0af813dbef4deb1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:16.970362500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fit KMeans and predict clusters\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(df2)\n",
    "\n",
    "# Calculate Davies-Bouldin Index\n",
    "dbi = davies_bouldin_score(df2, cluster_labels)\n",
    "print('Davies-Bouldin Index: %.3f' % dbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc364bb34b435f61",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### **Dimensionality Reduction Metrics**\n",
    "\n",
    "Dimensionality reduction aims to reduce the number of features while preserving the original information as much as possible. Because of that, many of the evaluation metrics in dimensionality reduction were all about information preservation. \n",
    " A good rule of thumb is to choose the number of components that gets you to a sufficiently high percentage of the total variance (often around 95% is used in practice). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e0efed5e59f20",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:16.980996500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Scaled the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df2)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(df_scaled)\n",
    "\n",
    "#Calculate Cumulative Explained Variance\n",
    "cev = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(range(1, len(cev) + 1), cev, marker='o')\n",
    "plt.xlabel('Number of PC')\n",
    "plt.ylabel('CEV')\n",
    "plt.title('CEV vs. Number of PC')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260ca25e2d0f83",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Based on this plot, it looks like a number of components around 7 would capture most of the variability in the data without including all of the components, thus achieving dimensionality reduction while retaining the essential characteristics of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2c054888ba94b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### **Trustworthiness**\n",
    "\n",
    "Trustworthiness is a measurement of the dimensionality reduction technique quality. This metric measured how well the reduced dimension preserved the original data nearest neighbor.\n",
    "\n",
    "Basically, the metric tries to see how well the dimension reduction technique preserved the data in maintaining the original data's local structure.\n",
    "\n",
    "The Trustworthiness metric ranges between 0 to 1, where values closer to 1 are means the neighbor that is close to reduced dimension data points are mostly close as well in the original dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41de60ad8aedf4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:16.991204800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Scale the data\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df2)\n",
    "\n",
    "# Step 2: Apply PCA for dimensionality reduction\n",
    "# You can decide how many components you want for PCA, let's say 2 for visualization\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Step 3: Calculate the trustworthiness of the low-dimensional projection\n",
    "# 'k' is a parameter and represents the number of neighbors to consider.\n",
    "# Common practice is to choose a value between 5 and 20.\n",
    "k = 5\n",
    "trust_score = trustworthiness(df_scaled, df_pca, n_neighbors=3)\n",
    "print('Trustworthiness: %.3f' % trust_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9caa11df8531",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### **Sammon’s Mapping**\n",
    "\n",
    "Sammon’s mapping is a non-linear dimensionality reduction technique to preserve the high-dimensionality pairwise distance when being reduced. \n",
    "The objective is to use Sammon’s Stress function to calculate the pairwise distance between the original data and the reduction space.\n",
    "\n",
    "The lower Sammon’s stress function score, the better because it indicates better pairwise preservation. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986983cdda50e408",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:17.003098100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df2 = df2.dropna() \n",
    "df2 = df2.drop_duplicates()\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df2)\n",
    "\n",
    "# Apply Sammon's mapping\n",
    "# e is the desired dimensionality of the output data (e.g., e=2 for 2D)\n",
    "# maxhalves and maxiter are parameters controlling the optimization process\n",
    "# maxhalves controls the number of step size halvings\n",
    "# maxiter controls the number of iterations\n",
    "# threshold is the threshold for convergence\n",
    "[e, y] = sammon.sammon(df_scaled, maxhalves=10, maxiter=500)\n",
    "\n",
    "print(f'Final value of the cost function: {e}')\n",
    "print(f'Coordinates of the points in the low-dimensional space: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32ad1ea8b2181d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Exclusive clustering\n",
    "\n",
    "### K-means clustering\n",
    "A data point can exist in only one cluster.\n",
    "\n",
    "Data points are assigned into K groups, where K represents the number of clusters based on the distance from each group’s centroid. The data points closest to a given centroid will be clustered under the same category.\n",
    "When K is bigger, the groups are smaller.\n",
    "When K is smaller, the groups are bigger.\n",
    "\n",
    "K-means clustering steps:\n",
    "\n",
    "1. Choose the number of clusters (K): First, decide how many clusters you want to identify in your data. This is represented by the variable K.\n",
    "2. Initialize cluster centroids: Randomly select K data points from the dataset to serve as the initial centroids of the clusters.\n",
    "3. Assign data points to nearest cluster: Calculate the distance between each data point and the centroids of the clusters. Assign each data point to the cluster with the nearest centroid.\n",
    "4. Update cluster centroids: Recalculate the centroids of the clusters based on the mean of the data points that belong to each cluster.\n",
    "5. Reassign data points to nearest cluster: Repeat the process of assigning each data point to the cluster with the closest centroid.\n",
    "6. Repeat steps 4 and 5 until convergence: Keep updating the centroids and reassigning the data points until the centroids no longer change significantly, or until a maximum number of iterations is reached.\n",
    "7. Finalize clusters: Once the algorithm converges, the data points will be divided into K clusters based on the final centroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805043670297517",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:15.187397300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df2 = pd.read_csv('data/online_shoppers_intention.csv', encoding=\"utf-8\")\n",
    "selected_columns = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration','BounceRates']\n",
    "\n",
    "df_selected = df2[selected_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_selected)\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=0, n_init=10)\n",
    "kmeans.fit(scaled_data)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "df2['cluster'] = labels\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Visualizing the clusters\n",
    "plt.scatter(principalComponents[labels == 0, 0], principalComponents[labels == 0, 1], s=50, c='red', label='Cluster 1')\n",
    "plt.scatter(principalComponents[labels == 1, 0], principalComponents[labels == 1, 1], s=50, c='blue', label='Cluster 2')\n",
    "plt.scatter(principalComponents[labels == 2, 0], principalComponents[labels == 2, 1], s=50, c='green', label='Cluster 3')\n",
    "plt.scatter(principalComponents[labels == 3, 0], principalComponents[labels == 3, 1], s=50, c='magenta', label='Cluster 4')\n",
    "\n",
    "# Plot the centroids of the clusters\n",
    "centroids = pca.transform(kmeans.cluster_centers_)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='yellow', label='Centroids', marker='x')\n",
    "plt.title('K-Means Clustering for Selected Columns')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d87732bb0536e8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "\n",
    "Overlapping clustering\n",
    "## Fuzzy k-means clustering\n",
    "\n",
    "Data points can belong to multiple clusters with varying degrees of membership (example: Fuzzy k-means).\n",
    "\n",
    "Instead of assigning each point completely to a cluster, the algorithm assigns membership coefficients to the point for different clusters. These coefficients represent the degree to which the data point belongs to each cluster.\n",
    "\n",
    "Fuzzy k-means clustering steps:\n",
    "\n",
    "1. Choose the number of clusters (K): Decide the number of clusters you want to identify in your data, represented by the variable K.\n",
    "2. Assign initial membership values: Initialize the degree of membership for each data point to each cluster randomly. These membership values indicate the degree to which a data point belongs to each cluster.\n",
    "3. Compute cluster centers: Calculate the centroids of the clusters based on the current membership values. These centroids are computed using a weighted average of the data points, where the weights are the membership values.\n",
    "4. Update membership values: Recompute the degree of membership for each data point to each cluster based on the current centroids. This is done using a formula that considers the distance between the data point and each cluster centroid.\n",
    "5. Repeat steps 3 and 4 until convergence: Iterate the process of updating the cluster centroids and membership values until the membership values converge or a maximum number of iterations is reached.\n",
    "6. Finalize clusters: Once the algorithm converges, the data points will have membership values for each cluster, indicating the degree of belongingness to each cluster. Based on these membership values, each data point can be assigned to one or more clusters, allowing for overlapping or fuzzy clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e00a7b2627d539",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:17.014247100Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/online_shoppers_intention.csv', encoding=\"utf-8\")\n",
    "selected_columns = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration','BounceRates']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_selected)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Fuzzy K-Means clustering\n",
    "centroids, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(\n",
    "    principalComponents.T, c=4, m=2, error=0.005, maxiter=1000, init=None\n",
    ")\n",
    "labels = np.argmax(u, axis=0)\n",
    "\n",
    "df['cluster'] = labels\n",
    "\n",
    "# Plotting the clusters\n",
    "plt.scatter(principalComponents[labels == 0, 0], principalComponents[labels == 0, 1], s=50, c='red', label='Cluster 1')\n",
    "plt.scatter(principalComponents[labels == 1, 0], principalComponents[labels == 1, 1], s=50, c='blue', label='Cluster 2')\n",
    "plt.scatter(principalComponents[labels == 2, 0], principalComponents[labels == 2, 1], s=50, c='green', label='Cluster 3')\n",
    "plt.scatter(principalComponents[labels == 3, 0], principalComponents[labels == 3, 1], s=50, c='magenta', label='Cluster 4')\n",
    " \n",
    "plt.scatter(centroids[0, 0], centroids[0, 1], s=300, c='yellow', marker='x')\n",
    "plt.scatter(centroids[1, 0], centroids[1, 1], s=300, c='yellow', marker='x')\n",
    "plt.scatter(centroids[2, 0], centroids[2, 1], s=300, c='yellow', marker='x')\n",
    "plt.scatter(centroids[3, 0], centroids[3, 1], s=300, c='yellow', marker='x')\n",
    "\n",
    "plt.title('Fuzzy K-Means Clustering')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b063d03418d38",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Hierarchical clustering\n",
    "\n",
    "Hierarchical clustering is beneficial for understanding the relationships and structures within complex datasets, as it provides an intuitive visualization of the data's inherent grouping patterns. Hierarchical clustering can be categorized into two main types: agglomerative and divisive. These two approaches represent different strategies for building the hierarchy of clusters.\n",
    "\n",
    "### Divisive Clustering\n",
    "Divisive Clustering, often known as the top-down approach, is the inverse of agglomerative clustering. It starts with a single cluster containing all data points and then progressively divides the cluster based on the dissimilarities among data points. This approach helps in uncovering the hierarchical structure within the dataset by iteratively splitting clusters into smaller subclusters.\n",
    "\n",
    "The primary objective of divisive clustering is to create clusters that are distinct from one another, ensuring that each division maximizes the dissimilarity between the resulting subclusters. By repeatedly splitting the clusters, this method enables the exploration of finer details and relationships present within the data.\n",
    "\n",
    "Divisive clustering is useful when dealing with large and complex datasets, as it allows for a comprehensive analysis of the data's underlying structure. However, this approach may require careful consideration of the criteria for splitting clusters to ensure the formation of meaningful and distinct subclusters.\n",
    "\n",
    "### Agglomerative Clustering\n",
    "\n",
    "Agglomerative Clustering, also known as the bottom-up approach, where data points begin as separate individual groupings and are progressively merged based on their similarities, ultimately leading to the formation of a single cluster. This approach helps reveal the inherent structure and relationships present within the dataset.\n",
    "There are various methods used within agglomerative clustering to determine the merging of clusters:\n",
    "- Ward’s Linkage: This method defines the distance between two clusters by considering the increase in the sum of squares after merging the clusters. It aims to minimize the variance within each cluster.\n",
    "- Average Linkage: The average linkage method calculates the mean distance between all pairs of points in different clusters and merges clusters with the smallest average distance.\n",
    "- Complete (or Maximum) Linkage: This method defines the distance between two clusters based on the maximum distance between any two points in the clusters.\n",
    "- Single (or Minimum) Linkage: In this method, the distance between two clusters is determined by the minimum distance between any two points in the clusters.\n",
    "- Centroid Linkage: This approach involves finding the centroids of each cluster and then calculating the distance between these centroids.\n",
    "\n",
    "Agglomerative clustering commonly employs the Euclidean distance metric to measure the distances between data points and clusters, providing a reliable means of evaluating the similarities or dissimilarities between various data points. This method is particularly useful in revealing the hierarchical relationships and structures within complex datasets.\n",
    "\n",
    "The example of Agglomerative Clustering is described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba17c8cacfe66ad7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:17.019647300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/online_shoppers_intention.csv', encoding=\"utf-8\")\n",
    "\n",
    "selected_columns = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration','BounceRates']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_selected)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(scaled_data)\n",
    "\n",
    "# Agglomerative Hierarchical Clustering\n",
    "clustering = AgglomerativeClustering(n_clusters=4, metric='euclidean', linkage='ward')\n",
    "labels = clustering.fit_predict(principalComponents)\n",
    "\n",
    "# Adding the labels to the dataframe\n",
    "df['cluster'] = labels\n",
    "\n",
    "# Plot the clusters \n",
    "plt.scatter(principalComponents[labels == 0, 0], principalComponents[labels == 0, 1], s=50, c='red', label='Cluster 1')\n",
    "plt.scatter(principalComponents[labels == 1, 0], principalComponents[labels == 1, 1], s=50, c='blue', label='Cluster 2')\n",
    "plt.scatter(principalComponents[labels == 2, 0], principalComponents[labels == 2, 1], s=50, c='green', label='Cluster 3')\n",
    "plt.scatter(principalComponents[labels == 3, 0], principalComponents[labels == 3, 1], s=50, c='magenta', label='Cluster 4')\n",
    "\n",
    "centroids = []\n",
    "for label in np.unique(labels):\n",
    "    centroids.append(np.mean(principalComponents[labels == label], axis=0))\n",
    "\n",
    "\n",
    "centroids = np.array(centroids)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], s=300, c='yellow', label='Centroids', marker='x') \n",
    "plt.title('Agglomerative Hierarchical Clustering with PCA')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65f882e4b6118d9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Probabilistic Clustering\n",
    "\n",
    "Probabilistic Clustering is a technique designed to address density estimation or \"soft\" clustering problems, wherein data points are clustered based on the probability or likelihood that they belong to a particular distribution.\n",
    "\n",
    "One of the prominent methods within probabilistic clustering is the use of Gaussian Mixture Models (GMMs). GMMs are classified as mixture models, comprising an unspecified number of probability distribution functions, often Gaussian or normal distributions. These models are instrumental in determining the probability that a given data point belongs to a specific Gaussian probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acb34e8188de07b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-22T22:48:17.024646800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "raw_df = pd.read_csv('data/CC GENERAL.csv', encoding=\"utf-8\")\n",
    "raw_df = raw_df.drop('CUST_ID', axis = 1) \n",
    "raw_df.ffill(inplace=True) \n",
    "\n",
    "# Standardize data\n",
    "scaler = StandardScaler() \n",
    "scaled_df = scaler.fit_transform(raw_df) \n",
    "\n",
    "# Normalizing the Data \n",
    "normalized_df = normalize(scaled_df) \n",
    "\n",
    "# Reducing the dimensions of the data \n",
    "pca = PCA(n_components = 2) \n",
    "X_principal = pca.fit_transform(normalized_df) \n",
    "X_principal = pd.DataFrame(X_principal) \n",
    "X_principal.columns = ['P1', 'P2'] \n",
    "\n",
    "# Perform Gaussian Mixture Model clustering\n",
    "gmm = GaussianMixture(n_components = 3) \n",
    "gmm.fit(X_principal)\n",
    "\n",
    "# Visualizing the clustering \n",
    "plt.scatter(X_principal['P1'], X_principal['P2'], c = gmm.predict(X_principal), cmap =plt.cm.winter, alpha = 0.6) \n",
    "\n",
    "# Visualizing the centroids\n",
    "centroids = gmm.means_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c='yellow', s=200, alpha=0.5, marker='x')\n",
    "\n",
    "plt.title('Clustering with Centroids')\n",
    "plt.xlabel('P1')\n",
    "plt.ylabel('P2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
