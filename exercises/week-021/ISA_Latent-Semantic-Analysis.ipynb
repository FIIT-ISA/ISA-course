{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4b7b2-c26c-40bd-88ed-9fdd0168839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809567e3c5c52a74",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Latent Semantic Analysis (LSA)\n",
    "\n",
    "**Sources:**\n",
    "- [Latent Semantic Analysis (LSA)](https://blog.marketmuse.com/glossary/latent-semantic-analysis-definition/#:~:text=Latent%20Semantic%20Analysis%20is%20a,relationships%20between%20terms%20and%20concepts)\n",
    "- https://www.datacamp.com/tutorial/discovering-hidden-topics-python\n",
    "\n",
    "**Latent Semantic Analysis (LSA)** is a Natural Language Processing (NLP) method that analyzes relationships between a set of documents and the terms contained within. It uses **Singular Value Decomposition (SVD)** method to scan unstructured data to find hidden relationships between terms and concepts.\n",
    "LSA is commonly used in NLP and in Information Retrieval (IR). \n",
    "By reducing the dimensionality of the term-document matrix, LSA enables the identification of hidden semantic concepts, facilitating tasks such as **document classification**, and **text summarization**.\n",
    "\n",
    "### How does LSA work?\n",
    "\n",
    "1. Create Term-Document Matrix: First, a term-document matrix is created, where rows represent terms (words) and columns represent documents. Each entry in the matrix indicates the frequency of a term in a particular document.\n",
    "\n",
    "2. Apply Singular Value Decomposition (SVD): LSA applies the SVD to the term-document matrix, decomposing it into three matrices: U, Σ, and V^T. U represents the relationship between terms and concepts, Σ contains the singular values, and V^T represents the relationship between documents and concepts.\n",
    "\n",
    "3. Dimensionality Reduction: LSA then reduces the dimensionality of the original matrix by selecting the top k singular values and their corresponding columns in U and V^T. This process helps to capture the most important underlying patterns and relationships in the data.\n",
    "\n",
    "4. Capture Latent Semantic Structure: By examining the relationships between the terms and documents in the reduced-dimensional space, LSA identifies the latent semantic structure, allowing for the discovery of underlying concepts or topics that are present across the document collection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652cd79c-e91f-430a-821c-8d7fcf007e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44dccd5d5fcda08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T20:52:07.359907400Z",
     "start_time": "2024-03-03T20:50:50.196654Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from gensim.models import LsiModel\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from file\n",
    "def load_data(file_path):\n",
    "    documents_list = []\n",
    "    titles = []\n",
    "    with open(file_path, \"r\") as fin:\n",
    "        for line in fin.readlines():\n",
    "            text = line.strip()\n",
    "            documents_list.append(text)\n",
    "            titles.append(text[0 : min(len(text), 100)])\n",
    "    return documents_list, titles\n",
    "\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(doc_set):\n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    en_stop = set(stopwords.words(\"english\"))\n",
    "    p_stemmer = PorterStemmer()\n",
    "    texts = []\n",
    "    for i in doc_set:\n",
    "        raw = i.lower()\n",
    "        tokens = tokenizer.tokenize(raw)\n",
    "        stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "        stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "        texts.append(stemmed_tokens)\n",
    "    return texts\n",
    "\n",
    "\n",
    "# Create dictionary and doc_term_matrix\n",
    "def prepare_corpus(doc_clean):\n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    return dictionary, doc_term_matrix\n",
    "\n",
    "\n",
    "# Create LSA model\n",
    "def create_gensim_lsa_model(doc_clean, number_of_topics, words):\n",
    "    dictionary, doc_term_matrix = prepare_corpus(doc_clean)\n",
    "    lsamodel = LsiModel(doc_term_matrix, num_topics=number_of_topics, id2word=dictionary)\n",
    "    print(\"LSA Model:\")\n",
    "    for idx, topic in lsamodel.print_topics(num_topics=number_of_topics, num_words=words):\n",
    "        print(f\"Topic-{idx + 1}: {topic}\")\n",
    "    return lsamodel\n",
    "\n",
    "\n",
    "# coherence values\n",
    "def compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, stop, step):\n",
    "        model = LsiModel(doc_term_matrix, num_topics=num_topics, id2word=dictionary)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=doc_clean, dictionary=dictionary, coherence=\"c_v\")\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values\n",
    "\n",
    "\n",
    "# coherence graph\n",
    "def plot_graph(doc_clean, start, stop, step):\n",
    "    dictionary, doc_term_matrix = prepare_corpus(doc_clean)\n",
    "    model_list, coherence_values = compute_coherence_values(dictionary, doc_term_matrix, doc_clean, stop, start, step)\n",
    "    x = range(start, stop, step)\n",
    "    plt.plot(x, coherence_values)\n",
    "    plt.xlabel(\"Number of Topics\")\n",
    "    plt.ylabel(\"Coherence score\")\n",
    "    plt.legend(\"coherence_values\", loc=\"best\")\n",
    "    plt.show()\n",
    "\n",
    "number_of_topics = 7\n",
    "words = 10\n",
    "\n",
    "# Load data and preprocess\n",
    "document_list, titles = load_data(\"data/lsa.txt\")\n",
    "clean_text = preprocess_data(document_list)\n",
    "\n",
    "start, stop, step = 2, 12, 1\n",
    "plot_graph(clean_text, start, stop, step)\n",
    "\n",
    "# LSA Model\n",
    "model = create_gensim_lsa_model(clean_text, number_of_topics, words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
