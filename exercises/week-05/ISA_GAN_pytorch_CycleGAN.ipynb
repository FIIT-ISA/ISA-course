{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CycleGAN example\n",
    "### Author: Marek Sunega (2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.cuda\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "solaw682S8US",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DATASET_PATH = \"dataset/\"\n",
    "MODEL_PATH = \"models/\"\n",
    "IMAGE_SAVE_PATH = \"generated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gtnQogh7rc7q",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plotRandomImg(image_paths, num_images = 5):\n",
    "    random_paths = random.sample(image_paths, num_images)\n",
    "\n",
    "    # Display the images\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    for i, img_path in enumerate(random_paths):\n",
    "        img = mpimg.imread(os.path.join(DATASET_PATH, img_path))\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(os.path.basename(img_path))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "vB-2Jka9pZ7b",
    "outputId": "9b45f7e1-8287-47d1-b51a-1218c806f84a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dfA = os.listdir(DATASET_PATH+\"A\")\n",
    "dfB = os.listdir(DATASET_PATH+\"B\")\n",
    "\n",
    "modified_paths_dfA = []\n",
    "for img_path in dfA:\n",
    "    modified_path = os.path.join(\"A\", img_path)  # Add \"_modified\" to each path\n",
    "    modified_paths_dfA.append(modified_path)\n",
    "\n",
    "modified_paths_dfB = []\n",
    "for img_path in dfB:\n",
    "    modified_path = os.path.join(\"B\", img_path)    # Add \"_modified\" to each path\n",
    "    modified_paths_dfB.append(modified_path)\n",
    "\n",
    "plotRandomImg(modified_paths_dfA)\n",
    "plotRandomImg(modified_paths_dfB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPi5bO83B9Qe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model generátora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwwCK281SVQj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, padding_mode=\"reflect\", **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(DeconvBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, **kwargs),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    # residual block\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            ConvBlock(in_channels, in_channels, kernel_size=3, padding=1),\n",
    "            ConvBlock(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.main(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.main = nn.Sequential(\n",
    "            ConvBlock(3, 64, kernel_size=7, padding=3),\n",
    "\n",
    "            # downsample\n",
    "            ConvBlock(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            ConvBlock(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "\n",
    "            # 9 residual blocks\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "\n",
    "            # upsample\n",
    "            DeconvBlock(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            DeconvBlock(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "\n",
    "            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3, padding_mode=\"reflect\")\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDx2yPcLCKF6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model klasifikátora - Diskriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QXhaYmO9Sr5U",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=stride, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            Block(64, 128, 2),\n",
    "            Block(128, 256, 2),\n",
    "            Block(256, 512, 1),\n",
    "\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1, padding_mode=\"reflect\"),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBKppoyGCR2T",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Štruktúra pre dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agK6fwXbYb-a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    # custom dataset class for dataloader\n",
    "    def __init__(self, root_a, root_b):\n",
    "        self.images_a = os.listdir(root_a)\n",
    "        self.images_a_len = len(self.images_a)\n",
    "        self.root_a = root_a\n",
    "\n",
    "        self.images_b = os.listdir(root_b)\n",
    "        self.images_b_len = len(self.images_b)\n",
    "        self.root_b = root_b\n",
    "        self.dataset_len = max(self.images_a_len, self.images_b_len)\n",
    "\n",
    "\n",
    "        # for training\n",
    "        self.preprocess  = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path_a = os.path.join(self.root_a, self.images_a[index % self.images_a_len])\n",
    "        image_a = Image.open(path_a).convert(\"RGB\")\n",
    "        image_a = self.preprocess(image_a)\n",
    "\n",
    "        path_b = os.path.join(self.root_b, self.images_b[index % self.images_b_len])\n",
    "        image_b = Image.open(path_b).convert(\"RGB\")\n",
    "        image_b = self.preprocess(image_b)\n",
    "\n",
    "        return image_a, image_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8cEeuS8B5Dy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trénovací cyklus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZAqwYtVzTLDu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(loader, disc1, disc2, gen1, gen2, disc_opt, gen_opt, parameters):\n",
    "    l1 = nn.L1Loss()\n",
    "    mse = nn.MSELoss()\n",
    "\n",
    "    fake_photo = None\n",
    "    fake_paint = None\n",
    "    num_epochs = parameters[\"N_EPOCHS\"]\n",
    "\n",
    "    disc1.train()\n",
    "    disc2.train()\n",
    "    gen1.train()\n",
    "    gen2.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "      for paint, photo in tqdm(loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "          paint = paint.to(DEVICE)\n",
    "          photo = photo.to(DEVICE)\n",
    "\n",
    "          fake_paint = gen1(photo)\n",
    "          fake_photo = gen2(paint)\n",
    "\n",
    "          # cycle loss\n",
    "          cycle_paint = gen1(fake_photo)\n",
    "          cycle_photo = gen2(fake_paint)\n",
    "          c1_loss = l1(paint, cycle_paint)\n",
    "          c2_loss = l1(photo, cycle_photo)\n",
    "\n",
    "          # train discriminators\n",
    "          d1_real = disc1(paint)\n",
    "          d1_fake = disc1(fake_paint.detach())\n",
    "          d1_real_l = mse(d1_real, torch.ones_like(d1_real))\n",
    "          d1_fake_l = mse(d1_fake, torch.zeros_like(d1_fake))\n",
    "          d1_l = (d1_real_l + d1_fake_l)/2\n",
    "\n",
    "          d2_real = disc2(photo)\n",
    "          d2_fake = disc2(fake_photo.detach())\n",
    "          d2_real_l = mse(d2_real, torch.ones_like(d2_real))\n",
    "          d2_fake_l = mse(d2_fake, torch.zeros_like(d2_fake))\n",
    "          d2_l = (d2_real_l + d2_fake_l)/2\n",
    "\n",
    "          d_loss = d1_l + d2_l\n",
    "          disc_opt.zero_grad()\n",
    "          d_loss.backward()\n",
    "          disc_opt.step()\n",
    "\n",
    "          # train generators\n",
    "          d1_fake = disc1(fake_paint)\n",
    "          d2_fake = disc2(fake_photo)\n",
    "          g1_loss = mse(d1_fake, torch.ones_like(d1_fake))\n",
    "          g2_loss = mse(d2_fake, torch.ones_like(d2_fake))\n",
    "\n",
    "          g_loss = g1_loss + g2_loss + ((c1_loss + c2_loss) * parameters[\"LAMBDA_CYCLE\"])\n",
    "\n",
    "          gen_opt.zero_grad()\n",
    "          g_loss.backward()\n",
    "          gen_opt.step()\n",
    "\n",
    "\n",
    "      if fake_photo is not None and fake_paint is not None:\n",
    "        save_image(fake_paint * 0.5 + 0.5, os.path.join(IMAGE_SAVE_PATH, f\"imgA_{epoch + 1}.png\"))\n",
    "        save_image(fake_photo * 0.5 + 0.5, os.path.join(IMAGE_SAVE_PATH, f\"imgB_{epoch + 1}.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr_AYhiGCYyQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxMF2u4TS_Wm",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save(model, optimizer, path):\n",
    "    savefile = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(savefile, path)\n",
    "\n",
    "\n",
    "def load(model, optimizer, learning_rate, path):\n",
    "    if DEVICE == \"cuda\":\n",
    "       savefile = torch.load(path)\n",
    "    else:\n",
    "        savefile = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(savefile[\"model\"])\n",
    "\n",
    "\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJH9tfzoCab4",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyperparametre a inicializácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2Bzt5J-Cvk5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"BATCH_SIZE\": 2,\n",
    "    \"LEARNING_RATE\": 0.0002,\n",
    "    \"N_EPOCHS\": 2,\n",
    "    \"LAMBDA_CYCLE\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnGUO1QBbjV4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# other datasets: http://efrosgans.eecs.berkeley.edu/cyclegan/datasets/\n",
    "\n",
    "dataset = ImageDataset(DATASET_PATH+\"/A\", root_b=DATASET_PATH+\"/B\")\n",
    "loader = DataLoader(dataset, batch_size=params[\"BATCH_SIZE\"], shuffle=True)\n",
    "\n",
    "disc1 = Discriminator().to(DEVICE)\n",
    "disc2 = Discriminator().to(DEVICE)\n",
    "gen1 = Generator().to(DEVICE)\n",
    "gen2 = Generator().to(DEVICE)\n",
    "\n",
    "disc_opt = optim.Adam(list(disc1.parameters())+list(disc2.parameters()), lr=params[\"LEARNING_RATE\"], betas=(0.5, 0.999))\n",
    "gen_opt = optim.Adam(list(gen1.parameters())+list(gen2.parameters()), lr=params[\"LEARNING_RATE\"], betas=(0.5, 0.999))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3Lg4flPCj0G",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Trénovanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zc1edGEBC0HC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train(loader, disc1, disc2, gen1, gen2, disc_opt, gen_opt, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Ukladanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save(disc1, disc_opt, MODEL_PATH+\"disc1.pth\")\n",
    "save(disc2, disc_opt, MODEL_PATH+\"disc2.pth\")\n",
    "save(gen1, gen_opt, MODEL_PATH+\"gen1.pth\")\n",
    "save(gen2, gen_opt, MODEL_PATH+\"gen2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Vizualizácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_path = \"dataset/A/2011-05-30 18_05_07.jpg\"\n",
    "\n",
    "gen = Generator().to(DEVICE)\n",
    "load(gen, gen_opt,0.002, path=MODEL_PATH+\"/gen2.pth\")\n",
    "gen.eval()\n",
    "\n",
    "preprocess  = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "img = Image.open(img_path).convert(\"RGB\")\n",
    "img = preprocess(img)\n",
    "\n",
    "output = gen(img)\n",
    "\n",
    "generated_image = output.squeeze().detach().cpu()\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(mpimg.imread(img_path))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(generated_image.permute(1, 2, 0) * 0.5 + 0.5)\n",
    "plt.title('Generated Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
