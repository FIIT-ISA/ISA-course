{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59281d-6837-444f-bf4c-363fb9cee10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d3720-cf98-439c-a399-b71d3da23827",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Name Entity Recognition (NER) \n",
    "\n",
    "**Sources:**\n",
    "- https://www.analyticsvidhya.com/blog/2021/11/a-beginners-introduction-to-ner-named-entity-recognition/\n",
    "- https://www.turing.com/kb/a-comprehensive-guide-to-named-entity-recognition\n",
    "\n",
    "Named Entity Recognition (NER), also known as segmentation, extraction, or identification of objects, is a task within **Natural Language Processing (NLP)** and **Artificial Intelligence (AI)**. It involves the identification and classification of specific information, known as entities, in the text. These objects can be individual words or groups of words consistently representing the same concept. \n",
    "\n",
    "The main goal of NER is to analyze unstructured text and identify named entities, and then organize them into predetermined categories, such as Organization, Person, Location, Time, or custom categories tailored to specific use cases, such as Healthcare Terms or Programming Language. This process enhances the usability of data for various purposes, such as data analysis, information retrieval, and knowledge graph construction.\n",
    " \n",
    "## Different NER Systems\n",
    "\n",
    "There are few different NER systems: rule-based, dictionary-based, machine learning (ML) based, and deep learning approaches. \n",
    "\n",
    "### Dictionary-based Systems\n",
    "This is the simplest NER approach. Here we will be having a dictionary that contains a collection of vocabulary. In this approach, basic string matching algorithms are used to check whether the entity is occurring in the given text to the items in the vocabulary. The method has limitations as it is required to update and maintain the dictionary used for the system.\n",
    "\n",
    "### Rule-based Systems\n",
    "Here, the model uses a pre-defined set of rules for information extraction. Mainly two types of rules are used, Pattern-based rules, which depend upon the morphological pattern of the words used, and context-based rules, which depend upon the context of the word used in the given text document.  \n",
    "\n",
    "- **Pattern-based rule:** We define a pattern-based rule that identifies names by looking for sequences of capitalized words. For example, a pattern-based rule might say that any sequence of two or more consecutive capitalized words (e.g., \"John Smith,\" \"Mary Jane Watson\") should be classified as a \"Person\" entity. This rule relies on the morphological pattern of capitalized words.\n",
    "\n",
    "- **Context-based rule:** We define context-based rules that consider the context in which words appear. For instance, we might create a rule that checks if a capitalized word appears after the salutation \"Mr.\" or \"Ms.\" (e.g., \"Mr. Smith,\" \"Ms. Watson\"). In such cases, we would classify the capitalized word as a \"Person\" entity based on the context.\n",
    "\n",
    "### Machine Learning-based Systems\n",
    "The ML-based systems use statistical-based models for detecting the entity names. These models try to make a feature-based representation of the observed data. By this approach, a lot of limitations of dictionary and rule-based approaches are solved by recognizing an existing entity name, even with small spelling variations.\n",
    "\n",
    "There are mainly two phases when we use an ML-based solution for NER. \n",
    "- The first phase involves training the ML model on the annotated documents.\n",
    "- In the next phase, the trained model can be used to annotate the corpus\n",
    "\n",
    "### Deep Learning Approaches\n",
    "\n",
    "**Key Components:** \n",
    "\n",
    "- **Distributed representations for input**: This step refers to methods used to convert words or characters into fixed-length vectors. These vectors represent the semantic meaning or value of each word or character in the context of natural language processing tasks. Such representations enable models to more efficiently process and understand textual information.\n",
    "\n",
    "- **Context encoder**: This is a component of the model that takes a sequence of words or characters as input and converts it into a contextual representation, considering the relationships and dependencies between the elements of the sequence. The context encoder helps the model understand the connections between words in a sentence or text, capturing the semantic and grammatical relationships between words.\n",
    "\n",
    "- **Tag decoder**: This is a component of the model responsible for predicting or decoding labels or tags for corresponding elements in the sequence. In the context of natural language processing tasks such as machine translation or Named Entity Recognition (NER), the tag decoder can be used to predict parts of speech, labels of predicted words, or other semantic labels related to the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bbc5fa-92eb-49c2-9433-2181802cdec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5775490e66c5492",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-03T21:02:52.484543600Z",
     "start_time": "2024-03-03T21:02:41.214029900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load text from a file\n",
    "file_path = 'ner.txt'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Set to keep track of seen entities\n",
    "seen_entities = set()\n",
    "\n",
    "# Extract and print unique named entities\n",
    "for ent in doc.ents:\n",
    "    if ent.text not in seen_entities:\n",
    "        seen_entities.add(ent.text)\n",
    "        print(f\"Entity: {ent.text}, Label: {ent.label_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
