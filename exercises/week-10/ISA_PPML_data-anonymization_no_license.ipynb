{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06dL0QTmSIrT"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i0HKhWadSIrU"
   },
   "source": [
    "# Data Anonymization\n",
    "\n",
    "## Data\n",
    "Healthcare cardiovascular dataset - original: [https://www.kaggle.com/datasets/sulianova/cardiovascular\\-disease\\-dataset/data](https://www.kaggle.com/datasets/sulianova/cardiovascular-disease-dataset/data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUaGLrC2SIrX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cardio_train_m.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xJusQv4SIrZ"
   },
   "source": [
    "## Exploratory Data Analysis (EDA) in Privacy-Preserving Machine Learning (PPML)\n",
    "\n",
    "Given the dataset description, there are several points to consider when it comes to PPML. The dataset contains a mix of identifiable personal information (like Full Name, Email, Address, Social Security number), objective features related to the individual's physical characteristics and health parameters, and subjective features that cover lifestyle choices.\n",
    "\n",
    "Before we proceed with any PPML techniques, we must categorize the data into identifiable, sensitive, and non-sensitive information. This categorization is crucial for determining the appropriate privacy-preserving methods.\n",
    "\n",
    "### Identifiable Information\n",
    "\n",
    "- **Id**\n",
    "- **Full Name**\n",
    "- **Email**\n",
    "- **Address**\n",
    "- **Social Security number (SSN)**\n",
    "\n",
    "These are direct identifiers and should be handled with the utmost care. This information can be used to directly trace back the data to the individuals. In most cases, this type of information should be removed or encrypted before the dataset is used for data mining purposes.\n",
    "\n",
    "### Sensitive Information\n",
    "\n",
    "- **Health data**: Age, Height, Weight, Systolic blood pressure, Diastolic blood pressure, Cholesterol, Glucose\n",
    "- **Lifestyle data**: Smoking, Alcohol intake, Physical activity\n",
    "- **Medical Outcome**: Presence or absence of cardiovascular disease\n",
    "\n",
    "This information, while not directly identifying, is still sensitive. It can potentially be used to infer identities, especially when combined with other data. For PPML, this data might need to be anonymized or perturbed.\n",
    "\n",
    "### Non-sensitive Information\n",
    "\n",
    "- **Gender**\n",
    "\n",
    "Gender may not be sensitive on its own, but in combination with other data, it can contribute to re-identification risk.\n",
    "\n",
    "### Steps for PPML on this dataset:\n",
    "\n",
    "1. **Anonymization by data transformation**: Remove or encrypt direct identifiers. For example, replace 'Full Name' with a pseudonym or random ID.\n",
    "\n",
    "2. **K-Anonymity**: Apply k-anonymity to the remaining quasi-identifiers like Age, Height, Weight, etc. This could mean generalizing ages to age ranges or height to height ranges.\n",
    "\n",
    "3. **L-Diversity**: Ensure that the anonymized data has sufficient diversity in the sensitive attributes. For instance, make sure that for every combination of age range and weight range, there are multiple records with different health conditions.\n",
    "\n",
    "4. **T-Closeness**: Maintain the distribution of sensitive attributes like Cholesterol and Glucose levels within each anonymized group close to the overall distribution to prevent skewness.\n",
    "\n",
    "5. **Data Perturbation**: Add noise to the data, especially for the numerical health-related features like blood pressure readings, to obscure the precise values but maintain the statistical distribution.\n",
    "\n",
    "6. **Minimize Data**: Only retain data necessary for the analysis. If the goal is to study cardiovascular disease patterns, data like 'Address' can be excluded entirely.\n",
    "\n",
    "7. **Access Control**: Ensure that only authorized personnel can access the de-identified dataset and that further use of the data is regulated. In our case this is not applicable as this is a study environment, however, in real life this might be crucial.\n",
    "\n",
    "In practice, you would need to balance data utility against privacy. The more you perturb the data to protect privacy, the less accurate your data mining results might be. It is crucial to find a point where the data is still useful for analysis without compromising individual privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Anonymization by data transformation\n",
    "\n",
    "**Remove Direct Identifiers**: We'll drop the `id`, `name`, `email` and `ssn` columns, as these contain directly identifiable information.\n",
    "\n",
    "**Data Tokenization**: Since we've removed almost all direct identifiers, we'll simulate tokenization by replacing `address` values with tokens. We will drop it later as we still don't need this field for cardiovascular analysis.\n",
    "\n",
    "**Data Generalization**: For attributes like `age` and `height`, we'll replace exact values with ranges.\n",
    "\n",
    "**Data Perturbation**: We'll apply a slight random noise to weight, `ap_hi`, and `ap_lo` to perturb these continuous variables.\n",
    "\n",
    "**Data Swapping**: We'll swap the values of `cholesterol` and `gluc` between records.\n",
    "\n",
    "**Noise Addition**: We'll add Gaussian noise to the `weight`.\n",
    "\n",
    "**Data Masking**: We'll replace `gender`, `smoke`, `alco`, and `active` with masked categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "25XyBKAPSIrc",
    "outputId": "bc2b4e75-ac48-49dc-dd38-1f62bcd65227"
   },
   "outputs": [],
   "source": [
    "# Remove Direct Identifiers\n",
    "data_anonymized = data.drop(columns=['id', 'name', 'email', 'ssn'])\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "BlzLjeehSIrd",
    "outputId": "a3d8fa9e-2668-4e13-9015-fb38dfa2ee9c"
   },
   "outputs": [],
   "source": [
    "# Data Tokenization\n",
    "import hashlib\n",
    "\n",
    "# Simulate data tokenization for the 'address' variable\n",
    "def generate_token(value):\n",
    "    # A simple tokenization using a hash function (not reversible in this case)\n",
    "    return hashlib.sha256(str(value).encode()).hexdigest()\n",
    "\n",
    "# Apply tokenization\n",
    "data_anonymized['address'] = data_anonymized['address'].apply(generate_token)\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7kuMitCRSIre",
    "outputId": "42abd326-c864-4819-c3b2-e4923d2de18e"
   },
   "outputs": [],
   "source": [
    "# Drop address, we no longer need it\n",
    "\n",
    "data_anonymized = data_anonymized.drop(columns=['address'])\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fHmj5mAQSIre",
    "outputId": "717d9876-3e1f-4bf1-eec2-549f107b9e13"
   },
   "outputs": [],
   "source": [
    "# Data Generalization or data aggraration = grouping data\n",
    "# Exapmle: Convert age from days to years\n",
    "\n",
    "data_anonymized['age'] = (data_anonymized['age'] / 365).astype(int)\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "dyFlR5VJSIrf",
    "outputId": "ab7d8931-d346-4672-a91d-4db16b77bf87"
   },
   "outputs": [],
   "source": [
    "# Create age ranges\n",
    "\n",
    "data_anonymized['age'] = pd.cut(data_anonymized['age'], bins=range(0, 110, 10), right=False)\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "7tCcBQfqSIrg",
    "outputId": "011affae-fc1c-410f-d65e-7a7b5a871c84"
   },
   "outputs": [],
   "source": [
    "# Create height ranges\n",
    "\n",
    "data_anonymized['height'] = pd.cut(data_anonymized['height'], bins=range(100, 250, 10), right=False)\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0K3yJpU2SIrg",
    "outputId": "c727ca54-4860-4f32-b7f2-e3f4f600b1d2"
   },
   "outputs": [],
   "source": [
    "# Data Perturbation\n",
    "\n",
    "# Define a function to add noise based on a percentage of the standard deviation\n",
    "def add_noise(series, noise_level):\n",
    "    return series + np.random.normal(0, noise_level * series.std(), size=len(series))\n",
    "\n",
    "# Apply the function to perturb the weight, ap_hi, and ap_lo\n",
    "data_anonymized['weight'] = add_noise(data_anonymized['weight'], 0.01)  # 1% noise\n",
    "data_anonymized['ap_hi'] = add_noise(data_anonymized['ap_hi'], 0.01)\n",
    "data_anonymized['ap_lo'] = add_noise(data_anonymized['ap_lo'], 0.01)\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xWwwm1pzSIrh",
    "outputId": "b995917f-1fb3-4439-e9aa-6615ebf79593"
   },
   "outputs": [],
   "source": [
    "# Data Swapping\n",
    "\n",
    "# Example: Randomly swap 'cholesterol' and 'gluc' between records\n",
    "cholesterol_indices = np.random.permutation(data_anonymized.index)\n",
    "gluc_indices = np.random.permutation(data_anonymized.index)\n",
    "\n",
    "data_anonymized['cholesterol'] = data_anonymized['cholesterol'].iloc[cholesterol_indices].values\n",
    "data_anonymized['gluc'] = data_anonymized['gluc'].iloc[gluc_indices].values\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JCobDpoaSIri",
    "outputId": "6a54cabc-ea39-4f44-a216-86f5f8b40725"
   },
   "outputs": [],
   "source": [
    "# Further Noise Addition (if needed)\n",
    "\n",
    "# We could add more noise to the 'ap_hi' and 'ap_lo' if we decide it's necessary. \n",
    "# But remember, the accuracy of predictions will also fall.\n",
    "\n",
    "data_anonymized['ap_hi'] = add_noise(data_anonymized['ap_hi'], 0.05)  # 5% noise\n",
    "data_anonymized['ap_lo'] = add_noise(data_anonymized['ap_lo'], 0.05)  # 5% noise\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xnUbM_lCSIri",
    "outputId": "f7c5399e-de76-47fa-f557-71b95274a105"
   },
   "outputs": [],
   "source": [
    "# Data Masking\n",
    "\n",
    "# Simple example of masking\n",
    "masking_tokens = {0: 'A', 1: 'B'}  \n",
    "\n",
    "# For binary attributes like 'smoke', 'alco', and 'active', we replace the actual values with assigned tokens\n",
    "data_anonymized['smoke'] = data_anonymized['smoke'].map(masking_tokens)\n",
    "data_anonymized['alco'] = data_anonymized['alco'].map(masking_tokens)\n",
    "data_anonymized['active'] = data_anonymized['active'].map(masking_tokens)\n",
    "data_anonymized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qRSlccYSIrj"
   },
   "source": [
    "# 2. K-anonymity\n",
    "\n",
    "**K-anonymity** is a privacy-preserving technique used to protect the identity of individuals in a dataset. The main goal is to ensure that each individual cannot be uniquely distinguished from at least **k−1** other individuals based on their attribute values.\n",
    "\n",
    "A dataset is said to be k-anonymous if the information for each person contained in the dataset cannot be distinguished from at least k−1 individuals whose information also appears in the dataset\n",
    "\n",
    "\n",
    "### K-anonymity limitations:\n",
    "\n",
    "If all the individuals in a k-anonymous set have the same sensitive value, then the sensitive value for the set is known. That is called a **homogeneity attack**.\n",
    "\n",
    "Imagine giving everyone in a neighborhood the same house color and car to make them less recognizable. Now, if all these look-alike folks also have the same health issue, for example, everyone has a sunburn, then if you know someone lives in that neighborhood, you'd guess they probably have a sunburn too. That's a homogeneity attack: when all the hidden data is too similar, it's easy to guess private stuff about someone if you know they're part of that group.\n",
    "\n",
    "The k-anonymity method tries to prevent this by making sure that each person's data is hidden in a group of at least 'k' people. But if all 'k' people have the same sensitive info, it doesn't help much. That's where **l-diversity** comes in. It's a fancier method that makes sure within each group, there's a mix of different sensitive details. So, even if you know someone is in a group, you can't be sure of their specific issue because there's a variety in there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FVHCwL3nSIrj",
    "outputId": "736ad949-9b2c-4774-95cb-b1f334a61477"
   },
   "outputs": [],
   "source": [
    "# Define k for k-anonymity check\n",
    "k = 5\n",
    "\n",
    "# Check for k-anonymity in age and height ranges\n",
    "age_k_anonymity = data_anonymized['age'].value_counts()\n",
    "height_k_anonymity = data_anonymized['height'].value_counts()\n",
    "\n",
    "# Check if all groups have at least k records\n",
    "age_k_anonymity_check = all(age_k_anonymity >= k)\n",
    "height_k_anonymity_check = all(height_k_anonymity >= k)\n",
    "\n",
    "# Output the results of the k-anonymity check\n",
    "age_k_anonymity_check, height_k_anonymity_check, age_k_anonymity, height_k_anonymity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2rjnWl_SIrk"
   },
   "source": [
    "The check for K-anonymity shows that our dataset does not satisfy K-anonymity for k=5 for both age and height ranges. There are groups, particularly at the extremes of the age and height ranges, that have fewer than 5 records.\n",
    "\n",
    "To achieve K-anonymity, we need to generalize these quasi-identifiers further. For example, we can combine less populous age and height groups with neighboring ones to ensure that each group has at least 5 records.\n",
    "\n",
    "Let's apply further generalization to ensure K-anonymity:\n",
    "\n",
    "- For the 'age' attribute, we'll combine the underrepresented ranges with the nearest populated range.\n",
    "- For 'height', we'll do the same by combining extreme ranges into broader categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NR7xeiUfSIrk",
    "outputId": "330b46e1-aea4-49d2-b955-db2972d68dfd"
   },
   "outputs": [],
   "source": [
    "# Correcting the approach to generalize 'age' and 'height' to satisfy k-anonymity\n",
    "\n",
    "# Function to extract the lower bound of the interval for re-binning\n",
    "def get_lower_bound(interval):\n",
    "    if pd.isnull(interval):\n",
    "        return np.nan\n",
    "    return interval.left\n",
    "\n",
    "# Apply the function to 'age' and 'height' to get the lower bound\n",
    "data_anonymized['age'] = data_anonymized['age'].apply(get_lower_bound)\n",
    "data_anonymized['height'] = data_anonymized['height'].apply(get_lower_bound)\n",
    "\n",
    "# Re-bin the 'age' and 'height' columns with new bins to satisfy k-anonymity\n",
    "age_bins = [0, 50, 60, 70, 120]  # Adjusted to combine underrepresented age groups\n",
    "height_bins = [0, 150, 170, 190, 250]  # Adjusted to combine underrepresented height groups\n",
    "\n",
    "data_anonymized['age'] = pd.cut(data_anonymized['age'], bins=age_bins, right=False)\n",
    "data_anonymized['height'] = pd.cut(data_anonymized['height'], bins=height_bins, right=False)\n",
    "\n",
    "# Re-check the k-anonymity after re-grouping\n",
    "age_k_anonymity = data_anonymized['age'].value_counts()\n",
    "height_k_anonymity = data_anonymized['height'].value_counts()\n",
    "\n",
    "# Check if all groups have at least k records after re-binning\n",
    "age_k_anonymity_check = all(age_k_anonymity >= k)\n",
    "height_k_anonymity_check = all(height_k_anonymity >= k)\n",
    "\n",
    "age_k_anonymity_check, height_k_anonymity_check, age_k_anonymity, height_k_anonymity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huPPW3xXSIrk"
   },
   "source": [
    "Now, after re-binning:\n",
    "\n",
    "- Height satisfies K-anonymity for k=5, as all height groups have at least 5 records.\n",
    "- Age still does not satisfy K-anonymity for k=5. The problem lies with the upper age group [70,120), which has no records at all, indicating that our age data does not extend into this range.\n",
    "\n",
    "To address this, we need to adjust the age bins to ensure that all populated age bins have at least k records. We'll combine the highest age range with the one below it to ensure compliance with K-anonymity. Let's adjust the age bins accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zGRWHin8SIrl",
    "outputId": "3c37ccf8-55c3-431e-d755-34ee0ee0f1b7"
   },
   "outputs": [],
   "source": [
    "# Extract the actual age values from the intervals again\n",
    "data_anonymized['age'] = data_anonymized['age'].apply(lambda x: x.left if pd.notnull(x) else x)\n",
    "\n",
    "# Adjust the age bins again to ensure k-anonymity\n",
    "# Combining the [60,70) and [70,120) age groups\n",
    "\n",
    "age_bins = [0, 50, 60, 120]  \n",
    "data_anonymized['age'] = pd.cut(data_anonymized['age'], bins=age_bins, right=False)\n",
    "\n",
    "# Re-check the k-anonymity for the 'age' attribute after re-binning\n",
    "age_k_anonymity = data_anonymized['age'].value_counts()\n",
    "age_k_anonymity_check = all(age_k_anonymity >= k)\n",
    "\n",
    "age_k_anonymity_check, age_k_anonymity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utx_lYueSIrl"
   },
   "source": [
    "Now, the k-anonymity for both columns seem to be implemented correctly. Let's check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "r2f4Zq3dSIrl",
    "outputId": "235886ad-721b-4429-9766-8970492f9cf5"
   },
   "outputs": [],
   "source": [
    "# Calculate the frequency of each combination of 'age' and 'height'\n",
    "\n",
    "# Extract the lower bound of the intervals to represent each record for re-binning if necessary\n",
    "data_anonymized['age_lower_bound'] = data_anonymized['age'].apply(lambda x: x.left)\n",
    "data_anonymized['height_lower_bound'] = data_anonymized['height'].apply(lambda x: x.left)\n",
    "\n",
    "# Group by the 'age' and 'height' ranges and calculate the counts\n",
    "k_anonymity_counts = data_anonymized.groupby(['age_lower_bound', 'height_lower_bound']).size().reset_index(name='counts')\n",
    "\n",
    "# Filter out the groups that do not meet k-anonymity (k=5)\n",
    "violations = k_anonymity_counts[k_anonymity_counts['counts'] < 5]\n",
    "\n",
    "violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VpG4bbpmSIrm"
   },
   "source": [
    "All combinations of 'age' and 'height' in the dataset now meet the k-anonymity criterion with **k=5**, as the dataframe showing the violations is empty. This means that for every combination of these quasi-identifiers, there are at least **five** records in the dataset, and we do not need to generalize these attributes further.\n",
    "\n",
    "### Evaluation of K-Anonymity\n",
    "\n",
    "To evaluate the k-anonymity of the dataset, we can ensure that no groups of records exist such that their count is less than **k**. Since our violations dataframe is empty, we can confirm that our dataset is kk-anonymous with respect to 'age' and 'height'.\n",
    "\n",
    "An additional evaluation metric could be the diversity of the sensitive attributes within each group defined by 'age' and 'height'. However, since we were focusing on these two attributes specifically for k-anonymity, and they are already compliant, we can conclude that the dataset satisfies k-anonymity for **k=5**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZCnEEsQSIrm"
   },
   "source": [
    "# 3. L-diversity\n",
    "\n",
    "**L-diversity** is a model that ***extends k-anonymity*** with the goal of reducing the granularity of data representation while maintaining diversity in the sensitive attributes within each group of k-anonymized records. L-diversity requires that each equivalence class (groups of records that are indistinguishable from each other with respect to certain quasi-identifiers) has at least ll \"well-represented\" values for the sensitive attributes.\n",
    "\n",
    "In the context of the dataset we are working with, sensitive attributes could include features such as 'weight', 'ap_hi', 'ap_lo', 'cholesterol', and 'gluc'. However, since 'weight', 'ap_hi', and 'ap_lo' have already been perturbed, focusing on 'cholesterol' and 'gluc' might be more relevant for L-diversity.\n",
    "\n",
    "**Here's how we'll implement L-diversity for the 'cholesterol' and 'gluc' attributes:**\n",
    "\n",
    "- For each combination of 'age' and 'height', we'll check the number of unique values of 'cholesterol' and 'gluc'.\n",
    "- If any group does not have at least 3 unique values for both 'cholesterol' and 'gluc', it violates L-diversity with **l=3**.\n",
    "- For any groups that violate L-diversity, we'll need to further generalize the quasi-identifiers or suppress records until the criterion is met.\n",
    "- We'll evaluate the L-diversity of the dataset after applying any necessary transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "rL963-2OSIrn",
    "outputId": "456f20cc-aafe-45b5-c943-47267b955fc9"
   },
   "outputs": [],
   "source": [
    "# Check the L-diversity for 'cholesterol' and 'gluc' within each k-anonymized group\n",
    "# Create a function to check if a group has l-diversity\n",
    "\n",
    "def check_l_diversity(group, column, l=3):\n",
    "    return group[column].nunique() >= l\n",
    "\n",
    "# Extraction of lower bounds for 'age' and 'height' intervals\n",
    "data_anonymized['age_lower_bound'] = data_anonymized['age'].apply(lambda x: x.left if pd.notnull(x) else x)\n",
    "data_anonymized['height_lower_bound'] = data_anonymized['height'].apply(lambda x: x.left if pd.notnull(x) else x)\n",
    "\n",
    "# Now let's check for l-diversity again\n",
    "l_diversity_violations = []\n",
    "\n",
    "for name, group in data_anonymized.groupby(['age_lower_bound', 'height_lower_bound']):\n",
    "    cholesterol_diverse = check_l_diversity(group, 'cholesterol', l=3)\n",
    "    gluc_diverse = check_l_diversity(group, 'gluc', l=3)\n",
    "    if not cholesterol_diverse or not gluc_diverse:\n",
    "        l_diversity_violations.append((name, cholesterol_diverse, gluc_diverse))\n",
    "\n",
    "# Create a DataFrame for violations for easier reading\n",
    "l_diversity_violations_df = pd.DataFrame(l_diversity_violations, columns=['Group', 'Cholesterol_Diverse', 'Gluc_Diverse'])\n",
    "\n",
    "l_diversity_violations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9cXdEjKSIrn"
   },
   "source": [
    "The output indicates that there are no groups that violate the l-diversity criterion for 'cholesterol' and 'gluc'. Each group of records, defined by the quasi-identifiers 'age' and 'height', has at least three well\\-represented values for both of these sensitive attributes.\n",
    "\n",
    "This confirms that the dataset complies with l-diversity with l=3, which means that the dataset is suitably anonymized with respect to these attributes within the context of the l-diversity privacy model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQbggKT7SIro"
   },
   "source": [
    "### Evaluation of l-diversity\n",
    "To evaluate l-diversity, we can use some metrics that will help us understand the level of diversity within each group of quasi-identifiers. Here are evaluation metrics we could consider:\n",
    "\n",
    "- **The average l-diversity of the dataset**: This is the average number of unique sensitive attribute values per group. A higher average indicates better privacy.\n",
    "\n",
    "- **The minimum l-diversity of the dataset**: This is the minimum number of unique sensitive attribute values in any group. For strict l-diversity compliance, this should be at least ll.\n",
    "\n",
    "- **The entropy of the sensitive attributes in each group**: Entropy measures the uncertainty or randomness of the information. Higher entropy is usually better for privacy because it indicates a higher degree of randomness in the sensitive attribute values. It is calculated using the following formula:\n",
    "\n",
    "$$\n",
    "Entropy = -\\sum_{i=1}^{n} p(x_i) \\log_2 p(x_i)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $n$ is the number of unique sensitive attribute values in the group.\n",
    "- $p(x_i)$ is the proportion of the group that has the \\( i \\)-th sensitive attribute value.\n",
    "- $\\log_2$ is the logarithm base 2, which is used to measure the entropy in bits.\n",
    "\n",
    "In l-diversity:\n",
    "\n",
    "- A higher entropy value for a group indicates a more diverse and thus a more \"private\" distribution of sensitive values, as it would be harder for an attacker to predict the value of the sensitive attribute for any individual within the group.\n",
    "- The goal is to ensure that the entropy is above a certain threshold for all groups defined by the combination of quasi-identifiers, which corresponds to ensuring a minimum level of l-diversity (where l is the minimum number of unique values).\n",
    "\n",
    "\n",
    "**Let's calculate these metrics for our dataset. We'll compute:**\n",
    "\n",
    "- The average number of unique values for 'cholesterol' and 'gluc' across all groups.\n",
    "- The minimum number of unique values for 'cholesterol' and 'gluc' across all groups.\n",
    "- The entropy of 'cholesterol' and 'gluc' values in each group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C0G20u6iSIrp",
    "outputId": "0283f2cd-7733-4bd5-8974-236c93c49671"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "# Calculate the average l-diversity for 'cholesterol' and 'gluc'\n",
    "unique_values_per_group = data_anonymized.groupby(['age_lower_bound', 'height_lower_bound'])[['cholesterol', 'gluc']].nunique()\n",
    "average_l_diversity = unique_values_per_group.mean()\n",
    "min_l_diversity = unique_values_per_group.min()\n",
    "\n",
    "# Calculate entropy for 'cholesterol' and 'gluc' in each group\n",
    "def calculate_entropy(group, column):\n",
    "    \n",
    "    # Count the frequency of each value\n",
    "    value_counts = group[column].value_counts()\n",
    "    \n",
    "    # Normalize to get probabilities\n",
    "    probabilities = value_counts / value_counts.sum()\n",
    "    \n",
    "    # Calculate entropy\n",
    "    return entropy(probabilities)\n",
    "\n",
    "# Apply entropy calculation for each group\n",
    "entropy_per_group = data_anonymized.groupby(['age_lower_bound', 'height_lower_bound']).apply(lambda g: pd.Series({\n",
    "    'Cholesterol_Entropy': calculate_entropy(g, 'cholesterol'),\n",
    "    'Gluc_Entropy': calculate_entropy(g, 'gluc')\n",
    "}))\n",
    "\n",
    "# Show the results\n",
    "(average_l_diversity, min_l_diversity, entropy_per_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qB_YcsP9SIrp"
   },
   "source": [
    "The results are as follows:\n",
    "\n",
    "- **Average l-diversity:**\n",
    "        For 'cholesterol': 3.0 unique values on average per group.\n",
    "        For 'gluc': 3.0 unique values on average per group.\n",
    "\n",
    "    Since the average number of unique values for both 'cholesterol' and 'gluc' is equal to 3, it meets our l-diversity criterion of l=3l=3 on average across the dataset.\n",
    "\n",
    "- **Minimum l-diversity:**\n",
    "        For 'cholesterol': 3 unique values in the least diverse group.\n",
    "        For 'gluc': 3 unique values in the least diverse group.\n",
    "\n",
    "    The minimum number of unique values for both 'cholesterol' and 'gluc' also meets our l-diversity criterion of l=3l=3, which indicates that every group has at least three different values for both sensitive attributes.\n",
    "\n",
    "- **Entropy of sensitive attributes:**\n",
    "        The entropy values for 'cholesterol' and 'gluc' vary across the groups, with some groups having higher entropy than others. Higher entropy values suggest a higher level of unpredictability or diversity within the group, which is desirable for privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2tSJe41RSIrp"
   },
   "source": [
    "# 4. T-closeness\n",
    "\n",
    "**T-closeness** is a privacy model that requires the distribution of a sensitive attribute in any group of records to be close to the distribution of the attribute in the overall dataset. \"Close\" is defined by a threshold tt, which is a distance measure between the two distributions.\n",
    "\n",
    "**Here are the steps we'll take to implement t-closeness:**\n",
    "\n",
    "- Calculate the overall distribution of the sensitive attributes 'cholesterol' and 'gluc'.\n",
    "- Calculate the distribution of 'cholesterol' and 'gluc' within each group.\n",
    "- Measure the distance between the two distributions for each group.\n",
    "- Determine if the distance is within a threshold tt, which is typically set based on domain knowledge or requirements.\n",
    "\n",
    "We will need to decide on a distance measure to use. A common choice is the Earth Mover's Distance (also known as the [Wasserstein metric](https://en.wikipedia.org/wiki/Wasserstein_metric)), but simpler measures like the absolute difference in proportions can also be used for illustrative purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JsfLlz9rSIrq",
    "outputId": "2e552905-4dcb-4ee4-a36b-322702e9f761"
   },
   "outputs": [],
   "source": [
    "# Calculate the overall distribution of the sensitive attributes 'cholesterol' and 'gluc'\n",
    "overall_cholesterol_distribution = data_anonymized['cholesterol'].value_counts(normalize=True)\n",
    "overall_gluc_distribution = data_anonymized['gluc'].value_counts(normalize=True)\n",
    "\n",
    "# Show the overall distributions\n",
    "(overall_cholesterol_distribution, overall_gluc_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FimNBGWbSIrq"
   },
   "source": [
    "The overall distributions for 'cholesterol' and 'gluc' are as follows:\n",
    "\n",
    "- For 'cholesterol':\n",
    "  - Value 1 (normal): 74.84%\n",
    "  - Value 2 (above normal): 13.64%\n",
    "  - Value 3 (well above normal): 11.52%\n",
    "\n",
    "- For 'gluc':\n",
    "  - Value 1 (normal): 84.97%\n",
    "  - Value 2 (above normal): 7.41%\n",
    "  - Value 3 (well above normal): 7.62%\n",
    "\n",
    "Next, we'll calculate the distribution of 'cholesterol' and 'gluc' within each group of records sharing the same combination of ***quasi-identifiers*** ('age' and 'height'). Then, we'll compare each group's distribution to the overall distribution to assess t-closeness. We need to select a threshold \\( t \\) that represents an acceptable difference between these distributions.\n",
    "\n",
    "For simplicity, let's calculate the absolute difference in proportions for each category of the sensitive attributes between the group and the overall dataset as a measure of distance. If the maximum difference for any value within a group exceeds \\( t \\), we'll consider it a violation of t-closeness.\n",
    "\n",
    "Let's proceed with this calculation. We'll use a threshold \\( t \\) of 0.2 for demonstration purposes, but this value should be carefully chosen based on the context and requirements of the data privacy needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "gktHm_vgSIrq",
    "outputId": "b18d8751-07b5-4233-fc42-6cf924bdf5c4"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the absolute difference in proportions for t-closeness\n",
    "def calculate_t_closeness(group_distribution, overall_distribution):\n",
    "    \n",
    "    # Align the group distribution with the overall distribution to ensure matching indices\n",
    "    group_distribution = group_distribution.reindex(overall_distribution.index, fill_value=0)\n",
    "    \n",
    "    # Calculate the absolute difference in proportions\n",
    "    return (group_distribution - overall_distribution).abs().max()\n",
    "\n",
    "# Initialize a list to track groups that violate t-closeness\n",
    "t_closeness_violations = []\n",
    "\n",
    "# Calculate t-closeness for each group\n",
    "for name, group in data_anonymized.groupby(['age_lower_bound', 'height_lower_bound']):\n",
    "    group_cholesterol_distribution = group['cholesterol'].value_counts(normalize=True)\n",
    "    group_gluc_distribution = group['gluc'].value_counts(normalize=True)\n",
    "\n",
    "    cholesterol_distance = calculate_t_closeness(group_cholesterol_distribution, overall_cholesterol_distribution)\n",
    "    gluc_distance = calculate_t_closeness(group_gluc_distribution, overall_gluc_distribution)\n",
    "\n",
    "    if cholesterol_distance > 0.2 or gluc_distance > 0.2:\n",
    "        t_closeness_violations.append((name, cholesterol_distance, gluc_distance))\n",
    "\n",
    "# Create a DataFrame for violations for easier reading\n",
    "t_closeness_violations_df = pd.DataFrame(t_closeness_violations, columns=['Group', 'Cholesterol_Distance', 'Gluc_Distance'])\n",
    "\n",
    "t_closeness_violations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7EcP-rxSIrr"
   },
   "source": [
    "### Evaluation of  t-closeness\n",
    "The evaluation for t-closeness has resulted in an empty DataFrame for violations, which means there are no groups where the absolute difference in proportions for 'cholesterol' and 'gluc' exceeds the threshold of 0.2. This indicates that with respect to the sensitive attributes 'cholesterol' and 'gluc', each group of records is similar to the overall dataset within the specified threshold, and thus, the dataset complies with t-closeness with t=0.2.\n",
    "\n",
    "This is a good outcome, as it suggests the dataset has been anonymized in a way that maintains the distribution of sensitive attributes close to the overall distribution, reducing the risk of attribute disclosure.\n",
    "\n",
    "#### T-closeness evaluation metrics in details:\n",
    "\n",
    "The Earth Mover's Distance (EMD) and Maximum Divergence are two measures that can be used to evaluate t-closeness between distributions.\n",
    "\n",
    "**Earth Mover's Distance (EMD)**   \n",
    "EMD, also known as the ***Wasserstein metric*** or ***Kantorovich metric***, is a measure of the distance between two probability distributions over a region D. Intuitively, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; that is, it is the minimum amount of work needed to transform one distribution into the other, where \"work\" is measured as the amount of distribution weight that must be moved, multiplied by the distance it has to be moved.\n",
    "\n",
    "The formula for EMD is more complex and typically requires linear programming to solve. It is given by:\n",
    "\n",
    "$ EMD(p, q) = \\inf_{\\gamma \\in \\Pi(p, q)} \\int_{D \\times D} d(x, y) \\, d\\gamma(x, y) $\n",
    "\n",
    "where:\n",
    "- $p$ and $q$ are the two probability distributions.\n",
    "- $\\gamma$ ranges over all possible joint distributions with marginals $p$ and $q$\n",
    "- $d(x, y)$ is the ground distance between points $x$ and $y$\n",
    "\n",
    "**Maximum Divergence**   \n",
    "The Maximum Divergence measures the maximum absolute difference between the probabilities of the same event under two different probability distributions.\n",
    "\n",
    "The formula for the Maximum Divergence is:\n",
    "\n",
    "$MaxDivergence(p, q) = \\max_{i} \\lvert p(x_i) - q(x_i) \\rvert$\n",
    "\n",
    "where:\n",
    "- $p$ and $q$ are the two probability distributions.\n",
    "- $x_i$ are the events for which the probabilities are compared.\n",
    "\n",
    "**Applying EMD and Max Divergence**   \n",
    "Python's `scipy.stats` library provides methods to calculate EMD, but the calculation of Maximum Divergence can be done manually since it's a simple max operation on the absolute difference of probabilities. We'll calculate both measures for our dataset.\n",
    "\n",
    "Let's apply these measures to compare the distributions of 'cholesterol' and 'gluc' within each group to the overall distribution. We will use the `wasserstein_distance` function from `scipy.stats` to calculate EMD. For the Maximum Divergence, we'll perform the calculation directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "kLnjAWxvSIrr",
    "outputId": "838c8141-7fe8-4198-ce10-d30b3a9f5d05"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "# Function to calculate the EMD and Max Divergence for t-closeness\n",
    "def calculate_emd_max_divergence(group_distribution, overall_distribution, categories):\n",
    "    \n",
    "    # Ensure the distributions are aligned and filled with zeros where necessary\n",
    "    aligned_group_dist = [group_distribution.get(x, 0) for x in categories]\n",
    "    aligned_overall_dist = [overall_distribution.get(x, 0) for x in categories]\n",
    "\n",
    "    # Calculate EMD\n",
    "    emd_value = wasserstein_distance(aligned_group_dist, aligned_overall_dist)\n",
    "\n",
    "    # Calculate Max Divergence\n",
    "    max_divergence_value = max(abs(a - b) for a, b in zip(aligned_group_dist, aligned_overall_dist))\n",
    "\n",
    "    return emd_value, max_divergence_value\n",
    "\n",
    "\n",
    "# Get the unique categories for cholesterol and gluc\n",
    "cholesterol_categories = overall_cholesterol_distribution.index.tolist()\n",
    "gluc_categories = overall_gluc_distribution.index.tolist()\n",
    "\n",
    "# Initialize a list to track the distances for each group\n",
    "t_closeness_metrics = []\n",
    "\n",
    "# Calculate EMD and Max Divergence for each group\n",
    "for name, group in data_anonymized.groupby(['age_lower_bound', 'height_lower_bound']):\n",
    "    group_cholesterol_distribution = group['cholesterol'].value_counts(normalize=True)\n",
    "    group_gluc_distribution = group['gluc'].value_counts(normalize=True)\n",
    "\n",
    "    cholesterol_emd, cholesterol_max_div = calculate_emd_max_divergence(group_cholesterol_distribution, overall_cholesterol_distribution, cholesterol_categories)\n",
    "    gluc_emd, gluc_max_div = calculate_emd_max_divergence(group_gluc_distribution, overall_gluc_distribution, gluc_categories)\n",
    "\n",
    "    t_closeness_metrics.append((name, cholesterol_emd, cholesterol_max_div, gluc_emd, gluc_max_div))\n",
    "\n",
    "# Create a DataFrame for the distances for easier reading\n",
    "t_closeness_metrics_df = pd.DataFrame(t_closeness_metrics, columns=['Group', 'Cholesterol_EMD', 'Cholesterol_MaxDiv', 'Gluc_EMD', 'Gluc_MaxDiv'])\n",
    "\n",
    "t_closeness_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoCwjdNTSIrr"
   },
   "source": [
    "The `t_closeness_metrics_df` DataFrame now contains the Earth Mover's Distance (EMD) and Maximum Divergence for 'cholesterol' and 'gluc' within each group, compared to the overall distribution.\n",
    "\n",
    "- **Cholesterol_EMD** and **Gluc_EMD** columns: These show the Earth Mover's Distance for 'cholesterol' and 'gluc' respectively. Smaller values indicate that the group's distribution is closer to the overall distribution.\n",
    "\n",
    "- **Cholesterol_MaxDiv** and **Gluc_MaxDiv** columns: These show the Maximum Divergence for 'cholesterol' and 'gluc' respectively. These values represent the maximum absolute difference in proportions for each value of the sensitive attributes between the group and the overall dataset. Smaller values are better, indicating a closer match to the overall distribution.\n",
    "\n",
    "From the DataFrame, we can see that most groups have relatively small EMD and Maximum Divergence values, suggesting that the distribution of 'cholesterol' and 'gluc' within these groups is not significantly different from the overall distribution. This indicates a good level of compliance with t-closeness.\n",
    "\n",
    "To evaluate whether these distances are acceptable, one would compare them to a predefined threshold \\( t \\). This threshold would depend on the specific privacy requirements and the context in which the data will be used.\n",
    "\n",
    "If any group's distance exceeds the acceptable threshold, further anonymization techniques would need to be applied to that group to reduce the distance and ensure compliance with t-closeness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_UTWSx11SIrs"
   },
   "outputs": [],
   "source": [
    "data_anonymized.to_csv('data_anonymized.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pcM4tzoSIrs"
   },
   "source": [
    "# 5. Information Loss\n",
    "\n",
    "**Information Loss (IL)** is a measure used to quantify the amount of data utility that is lost as a result of anonymization or data transformation. It reflects the loss of detail or accuracy in the data, which can impact the usefulness of the data for analysis. There are many ways to calculate information loss, depending on the type of data and the anonymization technique used.\n",
    "\n",
    "For continuous variables, we often use the **Root Mean Squared Error (RMSE)**, which is a measure of the differences between values predicted by a model or an estimator and the values observed. The RMSE for a set of values is the square root of the mean of the squares of the differences between the anonymized and original values.\n",
    "\n",
    "For continuous variables, the RMSE is defined as:\n",
    "\n",
    "$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (o_i - a_i)^2}\n",
    "$\n",
    "\n",
    "where $ o_i $ is the original value and $ a_i $ is the anonymized value for the $i^{th}$ observation.\n",
    "\n",
    "For categorical and binary variables, the proportion of changed values is calculated. This is simply the count of values that were changed by the anonymization process divided by the total number of values:\n",
    "\n",
    "$\n",
    "\\text{Proportion Changed} = \\frac{\\text{Number of changed values}}{n}\n",
    "$\n",
    "\n",
    "where $n$ is the total number of values.\n",
    "\n",
    "**To compute the information loss between the original cardio_train_m dataset and the data_anonymized dataset, we can use the following approach:**\n",
    "\n",
    "- Load the original cardio_train_m dataset and remove the direct identifiers.\n",
    "- Load the data_anonymized dataset and convert interval strings back to integer series (by extracting the lower bound, for example).\n",
    "- Align the datasets based on the indexes so that we can compare them directly.\n",
    "- Calculate information loss metrics for the quantitative and categorical attributes.\n",
    "\n",
    "For quantitative attributes (like weight, ap_hi, and ap_lo), we can calculate the information loss by measuring the average difference between the original and anonymized data. For categorical attributes and binary attributes (like gender, cholesterol, gluc, smoke, alco, active, and cardio), we can measure the information loss by the proportion of changed values.\n",
    "\n",
    "Let's start by loading both datasets and preparing them for the information loss calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzHFQOU9SIrt",
    "outputId": "e29d2def-16c2-4dd3-8639-8b192d4f70da"
   },
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "original_data_path = 'cardio_train_m.csv'\n",
    "original_data = pd.read_csv(original_data_path, delimiter=';')\n",
    "\n",
    "# Drop direct identifiers from the original dataset\n",
    "identifiers = ['id', 'name', 'email', 'address', 'ssn']\n",
    "original_data.drop(identifiers, axis=1, inplace=True)\n",
    "\n",
    "# Keep only the necessary columns in the original dataset\n",
    "necessary_columns = ['gender', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "original_data = original_data[necessary_columns]\n",
    "\n",
    "# Load the anonymized dataset\n",
    "anonymized_data_path = 'data_anonymized.csv'\n",
    "anonymized_data = pd.read_csv(anonymized_data_path)\n",
    "\n",
    "# Convert interval strings back to integer series for 'age' and 'height'\n",
    "anonymized_data['age'] = anonymized_data['age'].apply(lambda x: int(x[1:].split(',')[0]) if pd.notnull(x) else np.nan)\n",
    "anonymized_data['height'] = anonymized_data['height'].apply(lambda x: int(x[1:].split(',')[0]) if pd.notnull(x) else np.nan)\n",
    "\n",
    "# Remove the 'Unnamed: 0' column and any other non-necessary columns from the anonymized dataset\n",
    "anonymized_data.drop(['Unnamed: 0', 'age', 'height'], axis=1, inplace=True)\n",
    "\n",
    "# Show the first few rows of both datasets to ensure correctness\n",
    "(original_data.head(), anonymized_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtVYz0CCSIrt"
   },
   "source": [
    "Next, we will calculate the information loss for each column. \n",
    "- For continuous variables (weight, ap_hi, and ap_lo), we will calculate the Root Mean Squared Error (RMSE) to quantify information loss. \n",
    "- For categorical and binary variables (gender, cholesterol, gluc, smoke, alco, active, and cardio), we will calculate the proportion of changed values.\n",
    "\n",
    "Since the anonymized dataset has perturbed these values, we expect some level of information loss. For binary variables in the anonymized dataset represented by letters ('A', 'B'), we assume 'A' corresponds to 0 and 'B' to 1 to make a direct comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fg8eDJ7CSIru",
    "outputId": "fb2970f8-d98a-4765-f7cc-5c9d98cdada6"
   },
   "outputs": [],
   "source": [
    "# Function to calculate RMSE for continuous variables\n",
    "def rmse(original, anonymized):\n",
    "    return np.sqrt(((original - anonymized) ** 2).mean())\n",
    "\n",
    "# Function to calculate the proportion of changed values for categorical/binary variables\n",
    "def proportion_changed(original, anonymized):\n",
    "    return (original != anonymized).mean()\n",
    "\n",
    "# Replace 'A' with 0 and 'B' with 1 in the anonymized dataset for binary variables\n",
    "binary_columns = ['smoke', 'alco', 'active']\n",
    "anonymized_data[binary_columns] = anonymized_data[binary_columns].replace({'A': 0, 'B': 1})\n",
    "\n",
    "# Calculate information loss for continuous variables\n",
    "continuous_columns = ['weight', 'ap_hi', 'ap_lo']\n",
    "info_loss_continuous = {col: rmse(original_data[col], anonymized_data[col]) for col in continuous_columns}\n",
    "\n",
    "# Calculate information loss for categorical/binary variables\n",
    "categorical_columns = ['gender', 'cholesterol', 'gluc', 'smoke', 'alco', 'active', 'cardio']\n",
    "info_loss_categorical = {col: proportion_changed(original_data[col], anonymized_data[col]) for col in categorical_columns}\n",
    "\n",
    "(info_loss_continuous, info_loss_categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CM0ynkYSIru"
   },
   "source": [
    "The information loss for the continuous variables is quantified as RMSE:\n",
    "\n",
    "- **weight**: RMSE of approximately 0.14, indicating a minor average error in weight values after anonymization.\n",
    "- **ap_hi**: RMSE of approximately 7.84, indicating a moderate average error in systolic blood pressure values.\n",
    "- **ap_lo**: RMSE of approximately 9.56, indicating a moderate average error in diastolic blood pressure values.\n",
    "\n",
    "For the categorical and binary variables, the information loss is quantified as the proportion of changed values:\n",
    "\n",
    "- **gender, smoke, alco, active, cardio**: No information loss detected (0% changed values).\n",
    "- **cholesterol**: Approximately 40.84% of the values were changed during the anonymization.\n",
    "- **gluc**: Approximately 26.63% of the values were changed during the anonymization.\n",
    "\n",
    "This analysis suggests that the anonymization process has maintained the gender and binary lifestyle-related attributes (smoke, alco, active, cardio) very well, with no changes observed. However, there is significant alteration in the cholesterol and gluc attributes, which is expected due to the data swapping step applied during anonymization. The RMSE values for continuous variables indicate an acceptable level of information loss, given the goal of anonymizing the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s4xaUNmU8b9"
   },
   "source": [
    "# References\n",
    "- [Guidelines for Anonymization & Pseudonymization](https://ispo.newschool.edu/guidelines/anonymization-pseudonymization/#:~:text=To%20anonymize%20any%20dataset%2C%20sufficient,reasonably%20likely%20to%20be%20used.%E2%80%9D), 2019-2023\n",
    "- Ratra, Ritu & Gulia, Preeti. (2020). Privacy Preserving Data Mining: Techniques and Algorithms. International Journal of Engineering Trends and Technology. 68. 56-62. 10.14445/22315381/IJETT-V68I11P207. https://ijettjournal.org/archive/ijett-v68i11p207\n",
    "- GUIDE TO BASIC DATA ANONYMISATION TECHNIQUES (published 25 January 2018) - Personal Data Protection Commission Singapore (PDPC) https://www.pdpc.gov.sg/-/media/Files/PDPC/PDF-Files/Other-Guides/Guide-to-Anonymisation_v1-(250118).pdf\n",
    "- Agrawal, R. and Srikant, R., 2000, May. Privacy-preserving data mining. In Proceedings of the 2000 ACM SIGMOD international conference on Management of data (pp. 439-450). IBM Almaden Research Center. https://dl.acm.org/doi/pdf/10.1145/342009.335438"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
